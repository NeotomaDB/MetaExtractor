{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fossil Data Extraction Baselines\n",
    "\n",
    "This notebook sets up, runs and evaluates the baseline models for the fossil data extraction task.\n",
    "\n",
    "The data and baseline approaches are as follows:\n",
    "\n",
    "| **Entity Name**            | **Baseline Approach**                                              |\n",
    "|:---:|:---|\n",
    "| Geographic Location - GEOG | Regular Expressions (Goring et. al 2021)                                      |\n",
    "| Site Name - SITE           | spaCy Pre-Trained NER model identifying location entities |\n",
    "| Taxa - TAXA                | In-text search for existing taxa already in Neotoma                |\n",
    "| Age - AGE                  | Regular Expressions (Goring et. al 2021)                                      |\n",
    "| Altitude - ALTI            | Regular Expressions (\"above sea level\", \"a.s.l.\")                  |\n",
    "| Email Address(es) - EMAIL  | Regular Expressions                                                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# ensure that the parent directory is on the path for relative imports\n",
    "sys.path.append(os.path.join(os.path.abspath(''), \"..\"))\n",
    "\n",
    "from src.entity_extraction.baseline_entity_extraction import (\n",
    "    extract_geographic_coordinates,\n",
    "    extract_site_names,\n",
    "    extract_taxa,\n",
    "    extract_age,\n",
    "    extract_altitude,\n",
    "    extract_email,\n",
    "    baseline_extract_all\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Location - GEOG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coordinates of a site are often reported in the literature in a variety of formats. Few varying examples are:\n",
    "- 402646302N 0795855903W\n",
    "- 40:26:46.302N 079:58:55.903W\n",
    "- 40°26′46″N 079°58′56″W\n",
    "- 40d 26′ 46″ N 079d 58′ 56″ W\n",
    "- 40.446195N 79.982195W\n",
    "- 40.446195, -79.982195\n",
    "- 40.446195,-79.982195\n",
    "- 40° 26.7717, -79° 58.93172\n",
    "- N40:26:46.302 W079:58:55.903\n",
    "- N40°26′46″ W079°58′56″\n",
    "- N40d 26′ 46″ W079d 58′ 56″\n",
    "- N40.446195 W79.982195\n",
    "- 52°05.75′N, 131°13.25′W\n",
    "- 10°50'E, 46°51'N\n",
    "\n",
    "The baseline solution based off of Goring et. al 2021 uses regular expressions to identify coordinates. We've adpated and updated those regex patterns to reduce the number of false positive generated:\n",
    "1. Pattern for geographic coordinates - ```[-+]?[NESW\\d]+\\s?[NESWd\\.:°o◦'`\"″]\\s?[NESW]?\\d{1,7}\\s?[NESWd\\.:°o◦′'`\"″]?\\s?\\d{1,6}[[NESWd\\.:°o◦′'`\"″]?\\s?[NESW]?```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site Name - SITE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use pretrained ner models to extract location names from literature, but we are not sure whether these entities will correspond to `region_name` or `site_name`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxa - TAXA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline approach to extract taxas from full text journal articles is to perform string matching. Using an exhaustive list of all the taxas is present on the neotoma database, we search for the exact taxon names in literature. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age - AGE\n",
    "\n",
    "The age of samples is often reported in the literature in a variety of formats.  The most common formats are:\n",
    "- years BP - before present\n",
    "- kyr BP - 1000’s of years BP\n",
    "- ka BP - kilo annum BP\n",
    "- a BP - annum BP\n",
    "- Ma BP - million years BP\n",
    "- YBP - years BP\n",
    "\n",
    "In Neotoma there are three age columns, we have ageold, agetype and ageyoung.\n",
    "\n",
    "- agetype: Age type or units. Includes the following:\n",
    "  - Calendar years AD/BC\n",
    "  - Calendar years BP\n",
    "  - Calibrated radiocarbon years BP\n",
    "  - Radiocarbon years BP\n",
    "  - Varve years BP\n",
    "\n",
    "The baseline solution based off of Goring et. al 2021 uses regular expressions to:\n",
    "1. Identify the age entity in the sentence - `\" BP \"`\n",
    "2. Determine if it is a range of dates - `\"(\\\\d+(?:[.]\\\\d+)*) ((?:- {1,2})|(?:to)) (\\\\d+(?:[.]\\\\d+)*) ([a-zA-Z]+,BP\"`\n",
    "3. Extract the age entity from the sentence - `\"(\\\\d+(?:[.]\\\\d+)*),((?:- {1,2})|(?:to)),(\\\\d+(?:[.]\\\\d+)*),([a-zA-Z]+,BP),\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"1234 BP\",\n",
    "    \"1234 Ma BP\",\n",
    "    \"1234 to 1235 BP\",\n",
    "    \"1234 - 1235 BP\",\n",
    "    \"1234 -- 1235 BP\",\n",
    "    \"1234 BP and 456 to 789 BP\",\n",
    "    \"1234 BP and 456 to 789 Ma BP\",\n",
    "]\n",
    "\n",
    "expected_results = [\n",
    "    [{'start': 0, 'end': 7, 'label': ['AGE'], 'text': '1234 BP'}],\n",
    "    [{'start': 0, 'end': 10, 'label': ['AGE'], 'text': '1234 Ma BP'}],\n",
    "    [{'start': 0, 'end': 15, 'label': ['AGE'], 'text': '1234 to 1235 BP'}],\n",
    "    [{'start': 0, 'end': 14, 'label': ['AGE'], 'text': '1234 - 1235 BP'}],\n",
    "    [{'start': 0, 'end': 15, 'label': ['AGE'], 'text': '1234 -- 1235 BP'}],\n",
    "    [\n",
    "        {'start': 0, 'end': 7, 'label': ['AGE'], 'text': '1234 BP'}, \n",
    "        {'start': 12, 'end': 25, 'label': ['AGE'], 'text': '456 to 789 BP'}\n",
    "    ],\n",
    "    [\n",
    "        {'start': 0, 'end': 7, 'label': ['AGE'], 'text': '1234 BP'}, \n",
    "        {'start': 12, 'end': 28, 'label': ['AGE'], 'text': '456 to 789 Ma BP'}\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that all the test sentences are extracted correctly\n",
    "for i, sentence in enumerate(test_sentences):\n",
    "\n",
    "    extracted_ages = extract_age(sentence)\n",
    "\n",
    "    print(f\"Testing sentence: {sentence}\")\n",
    "    print(f\"Got: {extracted_ages}\\n\")\n",
    "    assert extracted_ages == expected_results[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altitude - ALTI\n",
    "\n",
    "To identify altitude descriptions the primary indicators are:\n",
    "- \"above sea level\"\n",
    "- \"a.s.l.\"\n",
    "- a single m as the last character after numbers or as a standalone word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"120m above sea level\",\n",
    "    \"120m a.s.l.\",\n",
    "    \"120 m above sea level\",\n",
    "    \"120 m a.s.l.\",\n",
    "    \"120m asl\",\n",
    "    \"120 m asl\",\n",
    "    \"The site was 120m above sea level\",\n",
    "    \"The site was 120m a.s.l.\",\n",
    "    \"The site was 120 m above sea level\",\n",
    "    \"The site was 120 m a.s.l.\",\n",
    "    \"First site was 120m asl and the second was 300 m asl\",\n",
    "]\n",
    "\n",
    "expected_results = [\n",
    "    [{'start': 0, 'end': 20, 'label': ['ALTI'], 'text': '120m above sea level'}],\n",
    "    [{'start': 0, 'end': 11, 'label': ['ALTI'], 'text': '120m a.s.l.'}],\n",
    "    [{'start': 0, 'end': 21, 'label': ['ALTI'], 'text': '120 m above sea level'}],\n",
    "    [{'start': 0, 'end': 12, 'label': ['ALTI'], 'text': '120 m a.s.l.'}],\n",
    "    [{'start': 0, 'end': 8, 'label': ['ALTI'], 'text': '120m asl'}],\n",
    "    [{'start': 0, 'end': 9, 'label': ['ALTI'], 'text': '120 m asl'}],\n",
    "    [{'start': 13, 'end': 33, 'label': ['ALTI'], 'text': '120m above sea level'}],\n",
    "    [{'start': 13, 'end': 24, 'label': ['ALTI'], 'text': '120m a.s.l.'}],\n",
    "    [{'start': 13, 'end': 34, 'label': ['ALTI'], 'text': '120 m above sea level'}],\n",
    "    [{'start': 13, 'end': 25, 'label': ['ALTI'], 'text': '120 m a.s.l.'}],\n",
    "    [\n",
    "        {'start': 15, 'end': 23, 'label': ['ALTI'], 'text': '120m asl'},\n",
    "        {'start': 43, 'end': 52, 'label': ['ALTI'], 'text': '300 m asl'}\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that all the test sentences are extracted correctly\n",
    "for i, sentence in enumerate(test_sentences):\n",
    "\n",
    "    extracted_altitude = extract_altitude(sentence)\n",
    "\n",
    "    print(f\"Testing sentence: {sentence}\")\n",
    "    print(f\"Found: {extracted_altitude}\\n\")\n",
    "    assert extracted_altitude == expected_results[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Addresses - EMAIL\n",
    "\n",
    "There are existing regex patterns developed to identify emails. The one used below was sourced from this StackoverFlow thread: \n",
    "- https://stackoverflow.com/questions/201323/how-can-i-validate-an-email-address-using-a-regular-expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"ty.elgin.andrews@gmail.com\",\n",
    "    \"john.smith@aol.com\",\n",
    "    \"ty.andrews@student.ubc.ca\",\n",
    "    # from GGD 54b4324ae138239d8684a37b segment 0\n",
    "    \"E-mail addresses : carina.hoorn@milne.cc (C. Hoorn -) mauro.cremaschi@libero.it\"\n",
    "]\n",
    "\n",
    "expected_results = [\n",
    "    [{'start': 0, 'end': 26, 'label': ['EMAIL'], 'text': 'ty.elgin.andrews@gmail.com'}],\n",
    "    [{'start': 0, 'end': 18, 'label': ['EMAIL'], 'text': 'john.smith@aol.com'}],\n",
    "    [{'start': 0, 'end': 25, 'label': ['EMAIL'], 'text': 'ty.andrews@student.ubc.ca'}],\n",
    "    [\n",
    "        {'start': 19, 'end': 40, 'label': ['EMAIL'], 'text': 'carina.hoorn@milne.cc'},\n",
    "        {'start': 54, 'end': 79, 'label': ['EMAIL'], 'text': 'mauro.cremaschi@libero.it'}\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(test_sentences):\n",
    "\n",
    "    extracted_emails = extract_email(sentence)\n",
    "\n",
    "    print(f\"Testing sentence: {sentence}\")\n",
    "    print(f\"Found: {extracted_emails}\\n\")\n",
    "    assert extracted_emails == expected_results[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Baseline Methods\n",
    "\n",
    "Multiple methods to evaluate the NER task are evaluated for a given report:\n",
    "1. Does the number instances of each category align with what is present in Neotoma?\n",
    "   1. For each article need to pull out the number of instances of each category for the given DOI/GDD id\n",
    "2. Does the number of instances of each category align with what has been labelled?\n",
    "   1. Using the team labelled reports, count the number of instances of each category for each report.\n",
    "3. Does the extracted locations align with the labelled locations?\n",
    "   1. This can be done with the Python package `seqeval` which is used to evaluate the performance of a sequence labeling tasks. ([`seqeval` Github](https://github.com/chakki-works/seqeval))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Raw & Labelled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "labelled_file_path = os.path.join(os.getcwd(), os.pardir, \"data\", \"labelled\", \"labelling-labelled\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Neotoma Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Entity Counts to Labelled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_files = os.listdir(labelled_file_path)\n",
    "\n",
    "# count the number of occurences of each label\n",
    "annotated_label_counts = defaultdict(int)\n",
    "baseline_label_counts = defaultdict(int)\n",
    "\n",
    "for file in labelled_files:\n",
    "    \n",
    "    with open(os.path.join(labelled_file_path, file), \"r\") as f:\n",
    "        task = json.load(f)\n",
    "\n",
    "    raw_text = task['task']['data']['text']\n",
    "    \n",
    "    # get the baseline annotations\n",
    "    baseline_result = baseline_extract_all(raw_text)\n",
    "    for baseline in baseline_result:\n",
    "        baseline_label_counts[baseline['label'][0]] += 1\n",
    "\n",
    "    annotation_result = task['result']\n",
    "    \n",
    "    for annotation in annotation_result:\n",
    "        annotated_label_counts[annotation['value']['labels'][0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the percentage of entities extracted by baseline vs annotated\n",
    "annotated_labels = list(annotated_label_counts.keys())\n",
    "annotated_counts = list(annotated_label_counts.values())\n",
    "\n",
    "baseline_counts = [baseline_label_counts[label] for label in annotated_labels]\n",
    "\n",
    "annotated_counts = np.array(annotated_counts)\n",
    "baseline_counts = np.array(baseline_counts)\n",
    "\n",
    "# make into a tidy dataframe with columns Label, Source, Count\n",
    "annotated_df = pd.DataFrame(\n",
    "    {\n",
    "        'Label': annotated_labels + annotated_labels,\n",
    "        'Source': ['Annotated'] * len(annotated_labels) + ['Baseline'] * len(annotated_labels),\n",
    "        'Count': np.concatenate([annotated_counts, baseline_counts])\n",
    "    }\n",
    ")\n",
    "\n",
    "fig = px.bar(\n",
    "    annotated_df,\n",
    "    x=\"Label\",\n",
    "    y=\"Count\",\n",
    "    color=\"Source\",\n",
    "    barmode='group',\n",
    "    # labels={'x': 'Labels', 'value': 'No. of Entities'},\n",
    "    title='Counts of Labels in Annotated and Baseline Results',\n",
    "    width=800,\n",
    ").update_layout(\n",
    "    xaxis={'categoryorder': 'total descending'}, \n",
    "    margin={'l': 0, 'r': 0, 't': 50, 'b': 0}, \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_extracted = baseline_counts / annotated_counts\n",
    "\n",
    "fig = px.bar(\n",
    "    x=annotated_labels, \n",
    "    y=percentage_extracted, \n",
    "    color=annotated_labels,\n",
    "    labels={'x': 'Labels', 'y': 'Percentage Extracted'},\n",
    "    title='Percentage of Entities Extracted by Baseline vs Annotated',\n",
    "    width=800,\n",
    "    text=np.round(percentage_extracted, 3)*100,\n",
    "    hover_name=annotated_labels,\n",
    ").update_layout(\n",
    "    xaxis={'categoryorder': 'total descending'},\n",
    "    margin={'l': 0, 'r': 0, 't': 50, 'b': 0},\n",
    "    yaxis={'tickformat': ',.0%'},\n",
    "    showlegend=False,\n",
    "    yaxis_range=[0, 1],\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci531",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
