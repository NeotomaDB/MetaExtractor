{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fossil Data Extraction Baselines\n",
    "\n",
    "This notebook sets up, runs and evaluates the baseline models for the fossil data extraction task.\n",
    "\n",
    "The data and baseline approaches are as follows:\n",
    "\n",
    "| **Entity Name**            | **Baseline Approach**                                              |\n",
    "|:---:|:---|\n",
    "| Geographic Location - GEOG | Regular Expressions (Goring et. al 2021)                                      |\n",
    "| Site Name - SITE           | spaCy Pre-Trained NER model identifying location entities |\n",
    "| Taxa - TAXA                | In-text search for existing taxa already in Neotoma                |\n",
    "| Age - AGE                  | Regular Expressions (Goring et. al 2021)                                      |\n",
    "| Altitude - ALTI            | Regular Expressions (\"above sea level\", \"a.s.l.\")                  |\n",
    "| Email Address(es) - EMAIL  | Regular Expressions                                                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import re\n",
    "\n",
    "# ensure that the parent directory is on the path for relative imports\n",
    "sys.path.append(os.path.join(os.path.abspath(''), \"..\"))\n",
    "\n",
    "from src.entity_extraction.baseline_entity_extraction import (\n",
    "    extract_geographic_coordinates,\n",
    "    extract_site_names,\n",
    "    extract_taxa,\n",
    "    extract_age,\n",
    "    extract_altitude,\n",
    "    extract_email,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Location - GEOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site Name - SITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxa - TAXA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age - AGE\n",
    "\n",
    "The age of samples is often reported in the literature in a variety of formats.  The most common formats are:\n",
    "- years BP - before present\n",
    "- kyr BP - 1000â€™s of years BP\n",
    "- ka BP - kilo annum BP\n",
    "- a BP - annum BP\n",
    "- Ma BP - million years BP\n",
    "- YBP - years BP\n",
    "\n",
    "In Neotoma there are three age columns, we have ageold, agetype and ageyoung.\n",
    "\n",
    "- agetype: Age type or units. Includes the following:\n",
    "  - Calendar years AD/BC\n",
    "  - Calendar years BP\n",
    "  - Calibrated radiocarbon years BP\n",
    "  - Radiocarbon years BP\n",
    "  - Varve years BP\n",
    "\n",
    "The baseline solution based off of Goring et. al 2021 uses regular expressions to:\n",
    "1. Identify the age entity in the sentence - `\" BP \"`\n",
    "2. Determine if it is a range of dates - `\"(\\\\d+(?:[.]\\\\d+)*) ((?:- {1,2})|(?:to)) (\\\\d+(?:[.]\\\\d+)*) ([a-zA-Z]+,BP\"`\n",
    "3. Extract the age entity from the sentence - `\"(\\\\d+(?:[.]\\\\d+)*),((?:- {1,2})|(?:to)),(\\\\d+(?:[.]\\\\d+)*),([a-zA-Z]+,BP),\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"1234 BP\",\n",
    "    \"1234 Ma BP\",\n",
    "    \"1234 to 1235 BP\",\n",
    "    \"1234 - 1235 BP\",\n",
    "    \"1234 -- 1235 BP\",\n",
    "    \"1234 BP and 456 to 789 BP\",\n",
    "    \"1234 BP and 456 to 789 Ma BP\",\n",
    "]\n",
    "\n",
    "expected_results = [\n",
    "    [{'start': 0, 'end': 7, 'label': ['AGE'], 'text': '1234 BP'}],\n",
    "    [{'start': 0, 'end': 10, 'label': ['AGE'], 'text': '1234 Ma BP'}],\n",
    "    [{'start': 0, 'end': 15, 'label': ['AGE'], 'text': '1234 to 1235 BP'}],\n",
    "    [{'start': 0, 'end': 14, 'label': ['AGE'], 'text': '1234 - 1235 BP'}],\n",
    "    [{'start': 0, 'end': 15, 'label': ['AGE'], 'text': '1234 -- 1235 BP'}],\n",
    "    [\n",
    "        {'start': 0, 'end': 7, 'label': ['AGE'], 'text': '1234 BP'}, \n",
    "        {'start': 12, 'end': 25, 'label': ['AGE'], 'text': '456 to 789 BP'}\n",
    "    ],\n",
    "    [\n",
    "        {'start': 0, 'end': 7, 'label': ['AGE'], 'text': '1234 BP'}, \n",
    "        {'start': 12, 'end': 28, 'label': ['AGE'], 'text': '456 to 789 Ma BP'}\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sentence: 1234 BP\n",
      "Got: [{'start': 0, 'end': 7, 'label': ['AGE'], 'text': '1234 BP'}]\n",
      "\n",
      "Testing sentence: 1234 Ma BP\n",
      "Got: [{'start': 0, 'end': 10, 'label': ['AGE'], 'text': '1234 Ma BP'}]\n",
      "\n",
      "Testing sentence: 1234 to 1235 BP\n",
      "Got: [{'start': 0, 'end': 15, 'label': ['AGE'], 'text': '1234 to 1235 BP'}]\n",
      "\n",
      "Testing sentence: 1234 - 1235 BP\n",
      "Got: [{'start': 0, 'end': 14, 'label': ['AGE'], 'text': '1234 - 1235 BP'}]\n",
      "\n",
      "Testing sentence: 1234 -- 1235 BP\n",
      "Got: [{'start': 0, 'end': 15, 'label': ['AGE'], 'text': '1234 -- 1235 BP'}]\n",
      "\n",
      "Testing sentence: 1234 BP and 456 to 789 BP\n",
      "Got: [{'start': 0, 'end': 7, 'label': ['AGE'], 'text': '1234 BP'}, {'start': 12, 'end': 25, 'label': ['AGE'], 'text': '456 to 789 BP'}]\n",
      "\n",
      "Testing sentence: 1234 BP and 456 to 789 Ma BP\n",
      "Got: [{'start': 0, 'end': 7, 'label': ['AGE'], 'text': '1234 BP'}, {'start': 12, 'end': 28, 'label': ['AGE'], 'text': '456 to 789 Ma BP'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test that all the test sentences are extracted correctly\n",
    "for i, sentence in enumerate(test_sentences):\n",
    "\n",
    "    extracted_ages = extract_age(sentence)\n",
    "\n",
    "    print(f\"Testing sentence: {sentence}\")\n",
    "    print(f\"Got: {extracted_ages}\\n\")\n",
    "    assert extracted_ages == expected_results[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altitude - ALTI\n",
    "\n",
    "To identify altitude descriptions the primary indicators are:\n",
    "- \"above sea level\"\n",
    "- \"a.s.l.\"\n",
    "- a single m as the last character after numbers or as a standalone word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"120m above sea level\",\n",
    "    \"120m a.s.l.\",\n",
    "    \"120 m above sea level\",\n",
    "    \"120 m a.s.l.\",\n",
    "    \"120m asl\",\n",
    "    \"120 m asl\",\n",
    "    \"The site was 120m above sea level\",\n",
    "    \"The site was 120m a.s.l.\",\n",
    "    \"The site was 120 m above sea level\",\n",
    "    \"The site was 120 m a.s.l.\",\n",
    "    \"First site was 120m asl and the second was 300 m asl\",\n",
    "]\n",
    "\n",
    "expected_results = [\n",
    "    [{'start': 0, 'end': 20, 'label': ['ALTI'], 'text': '120m above sea level'}],\n",
    "    [{'start': 0, 'end': 11, 'label': ['ALTI'], 'text': '120m a.s.l.'}],\n",
    "    [{'start': 0, 'end': 21, 'label': ['ALTI'], 'text': '120 m above sea level'}],\n",
    "    [{'start': 0, 'end': 12, 'label': ['ALTI'], 'text': '120 m a.s.l.'}],\n",
    "    [{'start': 0, 'end': 8, 'label': ['ALTI'], 'text': '120m asl'}],\n",
    "    [{'start': 0, 'end': 9, 'label': ['ALTI'], 'text': '120 m asl'}],\n",
    "    [{'start': 13, 'end': 33, 'label': ['ALTI'], 'text': '120m above sea level'}],\n",
    "    [{'start': 13, 'end': 24, 'label': ['ALTI'], 'text': '120m a.s.l.'}],\n",
    "    [{'start': 13, 'end': 34, 'label': ['ALTI'], 'text': '120 m above sea level'}],\n",
    "    [{'start': 13, 'end': 25, 'label': ['ALTI'], 'text': '120 m a.s.l.'}],\n",
    "    [\n",
    "        {'start': 15, 'end': 23, 'label': ['ALTI'], 'text': '120m asl'},\n",
    "        {'start': 43, 'end': 52, 'label': ['ALTI'], 'text': '300 m asl'}\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sentence: 120m above sea level\n",
      "Found: [{'start': 0, 'end': 20, 'label': ['ALTI'], 'text': '120m above sea level'}]\n",
      "\n",
      "Testing sentence: 120m a.s.l.\n",
      "Found: [{'start': 0, 'end': 11, 'label': ['ALTI'], 'text': '120m a.s.l.'}]\n",
      "\n",
      "Testing sentence: 120 m above sea level\n",
      "Found: [{'start': 0, 'end': 21, 'label': ['ALTI'], 'text': '120 m above sea level'}]\n",
      "\n",
      "Testing sentence: 120 m a.s.l.\n",
      "Found: [{'start': 0, 'end': 12, 'label': ['ALTI'], 'text': '120 m a.s.l.'}]\n",
      "\n",
      "Testing sentence: 120m asl\n",
      "Found: [{'start': 0, 'end': 8, 'label': ['ALTI'], 'text': '120m asl'}]\n",
      "\n",
      "Testing sentence: 120 m asl\n",
      "Found: [{'start': 0, 'end': 9, 'label': ['ALTI'], 'text': '120 m asl'}]\n",
      "\n",
      "Testing sentence: The site was 120m above sea level\n",
      "Found: [{'start': 13, 'end': 33, 'label': ['ALTI'], 'text': '120m above sea level'}]\n",
      "\n",
      "Testing sentence: The site was 120m a.s.l.\n",
      "Found: [{'start': 13, 'end': 24, 'label': ['ALTI'], 'text': '120m a.s.l.'}]\n",
      "\n",
      "Testing sentence: The site was 120 m above sea level\n",
      "Found: [{'start': 13, 'end': 34, 'label': ['ALTI'], 'text': '120 m above sea level'}]\n",
      "\n",
      "Testing sentence: The site was 120 m a.s.l.\n",
      "Found: [{'start': 13, 'end': 25, 'label': ['ALTI'], 'text': '120 m a.s.l.'}]\n",
      "\n",
      "Testing sentence: First site was 120m asl and the second was 300 m asl\n",
      "Found: [{'start': 15, 'end': 23, 'label': ['ALTI'], 'text': '120m asl'}, {'start': 43, 'end': 52, 'label': ['ALTI'], 'text': '300 m asl'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test that all the test sentences are extracted correctly\n",
    "for i, sentence in enumerate(test_sentences):\n",
    "\n",
    "    extracted_altitude = extract_altitude(sentence)\n",
    "\n",
    "    print(f\"Testing sentence: {sentence}\")\n",
    "    print(f\"Found: {extracted_altitude}\\n\")\n",
    "    assert extracted_altitude == expected_results[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Addresses - EMAIL\n",
    "\n",
    "There are existing regex patterns developed to identify emails. The one used below was sourced from this StackoverFlow thread: \n",
    "- https://stackoverflow.com/questions/201323/how-can-i-validate-an-email-address-using-a-regular-expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"ty.elgin.andrews@gmail.com\",\n",
    "    \"john.smith@aol.com\",\n",
    "    \"ty.andrews@student.ubc.ca\",\n",
    "    # from GGD 54b4324ae138239d8684a37b segment 0\n",
    "    \"E-mail addresses : carina.hoorn@milne.cc (C. Hoorn -) mauro.cremaschi@libero.it\"\n",
    "]\n",
    "\n",
    "expected_results = [\n",
    "    [{'start': 0, 'end': 26, 'label': ['EMAIL'], 'text': 'ty.elgin.andrews@gmail.com'}],\n",
    "    [{'start': 0, 'end': 18, 'label': ['EMAIL'], 'text': 'john.smith@aol.com'}],\n",
    "    [{'start': 0, 'end': 25, 'label': ['EMAIL'], 'text': 'ty.andrews@student.ubc.ca'}],\n",
    "    [\n",
    "        {'start': 19, 'end': 40, 'label': ['EMAIL'], 'text': 'carina.hoorn@milne.cc'},\n",
    "        {'start': 54, 'end': 79, 'label': ['EMAIL'], 'text': 'mauro.cremaschi@libero.it'}\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sentence: ty.elgin.andrews@gmail.com\n",
      "Found: [{'start': 0, 'end': 26, 'label': ['EMAIL'], 'text': 'ty.elgin.andrews@gmail.com'}]\n",
      "\n",
      "Testing sentence: john.smith@aol.com\n",
      "Found: [{'start': 0, 'end': 18, 'label': ['EMAIL'], 'text': 'john.smith@aol.com'}]\n",
      "\n",
      "Testing sentence: ty.andrews@student.ubc.ca\n",
      "Found: [{'start': 0, 'end': 25, 'label': ['EMAIL'], 'text': 'ty.andrews@student.ubc.ca'}]\n",
      "\n",
      "Testing sentence: E-mail addresses : carina.hoorn@milne.cc (C. Hoorn -) mauro.cremaschi@libero.it\n",
      "Found: [{'start': 19, 'end': 40, 'label': ['EMAIL'], 'text': 'carina.hoorn@milne.cc'}, {'start': 54, 'end': 79, 'label': ['EMAIL'], 'text': 'mauro.cremaschi@libero.it'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(test_sentences):\n",
    "\n",
    "    extracted_emails = extract_email(sentence)\n",
    "\n",
    "    print(f\"Testing sentence: {sentence}\")\n",
    "    print(f\"Found: {extracted_emails}\\n\")\n",
    "    assert extracted_emails == expected_results[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci531",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
