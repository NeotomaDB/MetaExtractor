{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_new_gdd_articles(output_path, n_recent_articles = None, min_date = None, max_date = None):\n",
    "    \"\"\" \n",
    "    Get newly acquired articles from min_date to (optional) max_date. \n",
    "    Or get the most recent new articles added to GeoDeepDive.\n",
    "    Return API resuls as a list of article metadata information.\n",
    "\n",
    "    Example:\n",
    "    get_new_gdd_articles(min_date='2023-06-07')\n",
    "    get_new_gdd_articles(min_date='2023-06-01', max_date = '2023-06-08')\n",
    "    get_new_gdd_articles(n_recent_articles = 1000)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # ======== Tests for input data type ==========\n",
    "    if n_recent_articles is not None:\n",
    "        if min_date is None and max_date is None:\n",
    "            if isinstance(n_recent_articles, int) or isinstance(n_recent_articles, float):\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(\"When n_recent_articles is specified, it should be a numeric value.\")\n",
    "        else:\n",
    "            raise ValueError(\"When n_recent_articles is specified, min_data and max_date should be None.\")\n",
    "        \n",
    "    else: # n_recent_articles is None, should specify dates\n",
    "        if min_date is None:\n",
    "            raise ValueError(\"Either n_recent_articles or min_date should be specified\")\n",
    "        else:\n",
    "            pattern = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "\n",
    "            if not isinstance(min_date, str):\n",
    "                raise ValueError(\"min_date should be a string. min_date should be a string with format 'yyyy-mm-dd'.\")\n",
    "            if re.match(pattern, min_date) is False:\n",
    "                raise ValueError(\"min_date does not follow the correct format. min_date should be a string with format 'yyyy-mm-dd'.\")\n",
    "            \n",
    "            if max_date is not None:\n",
    "                if not isinstance(max_date, str):\n",
    "                    raise ValueError(\"max_date should be a string. min_max_datedate should be a string with format 'yyyy-mm-dd'.\")\n",
    "                if re.match(pattern, max_date) is False:\n",
    "                    raise ValueError(\"max_date should be a string with format 'yyyy-mm-dd'.\")\n",
    "\n",
    "    # ========== Query API by n most recent article ==========\n",
    "    if n_recent_articles is not None:\n",
    "        api_call = \"https://geodeepdive.org/api/articles?recent\" + f\"&max={n_recent_articles}\"\n",
    "\n",
    "    # Query API by date range\n",
    "    elif min_date is not None:\n",
    "        if max_date is not None:\n",
    "            api_call = f\"https://xdd.wisc.edu/api/articles?min_acquired={min_date}&max_acquired={max_date}\"\n",
    "        \n",
    "        else:\n",
    "            api_call = f\"https://xdd.wisc.edu/api/articles?min_acquired={min_date}\"\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Either n_recent_articles or min_date should be specified\")\n",
    "    \n",
    "\n",
    "    # =========== Format the API return to Json file ==========\n",
    "    response = requests.get(api_call).json()\n",
    "\n",
    "    data = response['success']['data']\n",
    "\n",
    "    # initialize the resulting dataframe\n",
    "    gdd_df = pd.DataFrame()\n",
    "\n",
    "    for article in data:\n",
    "        one_article_dict = {}\n",
    "        one_article_dict['_gddid'] = [article['_gddid']]\n",
    "\n",
    "        if article['identifier'][0]['type'] == 'doi':\n",
    "            one_article_dict['DOI'] = [article['identifier'][0]['id']]\n",
    "        else: \n",
    "            one_article_dict['DOI'] = ['Non-DOI Article ID type']\n",
    "        \n",
    "        one_article_dict['url'] = [article['link'][0]['url']]\n",
    "        one_article_dict['status'] = 'queried'\n",
    "\n",
    "        one_article = pd.DataFrame(one_article_dict)\n",
    "        gdd_df = pd.concat([gdd_df, one_article])\n",
    "    \n",
    "    gdd_df = gdd_df.reset_index(drop=True)\n",
    "\n",
    "    result_dict = {}\n",
    "    result_dict['n_returned_article'] = gdd_df.shape[0]\n",
    "    result_dict['param_min_date'] = min_date\n",
    "    result_dict['param_max_date'] = max_date\n",
    "    result_dict['param_n_recent_articles'] = n_recent_articles\n",
    "    result_dict['data'] = gdd_df.to_dict()\n",
    "\n",
    "    # Write the JSON object to a file\n",
    "    with open(output_path + '/gdd_api_return.json', \"w\") as file:\n",
    "        json.dump(result_dict, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossref_extract(doi_path):\n",
    "    \"\"\"Extract metadata from the Crossref API for article's in the doi csv file.\n",
    "    Extracted data are returned in a pandas dataframe.\n",
    "\n",
    "    If certain DOI is not found on CrossRef, the DOI will be logged in the prediction_pipeline.log file. \n",
    "    \n",
    "    Args:\n",
    "        doi_path (str): Path to the doi list csv file.\n",
    "        doi_col (str): Column name of DOI.\n",
    "    \n",
    "    Return:\n",
    "        pandas Dataframe containing CrossRef metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(doi_path) as json_file:\n",
    "        data_dictionary = json.load(json_file)\n",
    "\n",
    "    df = pd.DataFrame(data_dictionary['data'])\n",
    "    doi_col = 'DOI'\n",
    "\n",
    "    # a list of doi\n",
    "    input_doi = df[doi_col].unique().tolist()\n",
    "\n",
    "    # Initialize\n",
    "    crossref = pd.DataFrame()\n",
    "\n",
    "    # Loop through all doi, concatenate metadata into dataframe\n",
    "    for doi in input_doi:\n",
    "        cross_ref_url = f\"https://api.crossref.org/works/{doi}\"\n",
    "\n",
    "         # make a request to the API\n",
    "        cross_ref_response = requests.get(cross_ref_url)\n",
    "\n",
    "        if cross_ref_response.status_code == 200:\n",
    "\n",
    "            ref_json = pd.DataFrame(cross_ref_response.json())            \n",
    "            ref_df = pd.DataFrame(ref_json.loc[:, 'message']).T.reset_index()\n",
    "            ref_df['valid_for_prediction'] = 1\n",
    "            if 'abstract' not in ref_df.columns:\n",
    "                ref_df['abstract'] = ''\n",
    "\n",
    "            crossref = pd.concat([crossref, ref_df])\n",
    "\n",
    "        else: \n",
    "            pass\n",
    "    \n",
    "    # Clean up columns and return the resulting pandas data frame\n",
    "    crossref_keep_col = ['valid_for_prediction', 'DOI',\n",
    "        'URL',\n",
    "        'abstract',\n",
    "        'author',\n",
    "        'container-title',\n",
    "        'is-referenced-by-count', # times cited\n",
    "        'language',\n",
    "        'published', # datetime\n",
    "        'publisher', \n",
    "        'subject', # keywords of journal\n",
    "        'subtitle', # subtitle are missing sometimes\n",
    "        'title'\n",
    "        ]\n",
    "    \n",
    "    crossref = crossref.loc[:, crossref_keep_col].reset_index(drop = True)\n",
    "\n",
    "\n",
    "    # join gdd_id to the metadata df\n",
    "    print(df.columns)\n",
    "    df = df.loc[:, [doi_col, 'gddid']]\n",
    "    df['DOI'] = df['DOI'].str.lower() # CrossRef return lowercase DOI\n",
    "    result_df = pd.merge(df, crossref, on='DOI', how='left')\n",
    "    result_df = result_df.rename(columns = {'container-title': 'journal'})\n",
    "\n",
    "    # Add valid_for_prediction indicator\n",
    "    result_df['valid_for_prediction'] = result_df['valid_for_prediction'].fillna(value=0).astype(int)\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "min_date = '2023-06-05'\n",
    "api_call = f\"https://xdd.wisc.edu/api/articles?min_acquired={min_date}&full_results=true\"\n",
    "\n",
    "response = requests.get(api_call).json()\n",
    "\n",
    "data = response['success']['data']\n",
    "type(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda3/envs/591/lib/python3.10/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39;49mloads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/591/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/591/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/591/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m min_date \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m2023-06-05\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      3\u001b[0m api_call \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://xdd.wisc.edu/api/articles?min_acquired=\u001b[39m\u001b[39m{\u001b[39;00mmin_date\u001b[39m}\u001b[39;00m\u001b[39m&full_results=true\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(api_call)\u001b[39m.\u001b[39;49mjson()\n\u001b[1;32m      6\u001b[0m next_page \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39msuccess\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mnext_page\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39m# limit 3 times max\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/591/lib/python3.10/site-packages/requests/models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39mloads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[39m.\u001b[39mmsg, e\u001b[39m.\u001b[39mdoc, e\u001b[39m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "min_date = '2023-06-05'\n",
    "\n",
    "api_call = f\"https://xdd.wisc.edu/api/articles?min_acquired={min_date}&full_results=true\"\n",
    "\n",
    "response = requests.get(api_call).json()\n",
    "next_page = response['success']['next_page']\n",
    "\n",
    "i = 0 # limit 3 times max\n",
    "\n",
    "while (next_page != '') and (i < 3):\n",
    "    print(f\"going to the next page at {next_page}\")\n",
    "    next_response = requests.get(next_page)\n",
    "    print('=========next response done=========')\n",
    "    print(next_response)\n",
    "    next_response_json = next_response.json()\n",
    "    print('=========next response json done=========')\n",
    "\n",
    "    data.append(next_response_json['success']['data'])\n",
    "    \n",
    "    print(f\"There are {len(data)} articles.\")\n",
    "\n",
    "    next_page = next_response_json['success']['next_page']\n",
    "    i += 1\n",
    "\n",
    "    print(f\"next page is now {next_page}, iteration {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [502]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://xdd.wisc.edu/api/articles\"\n",
    "params = {\"scroll_id\": \"08e46e34-2878-4e57-8fe5-72182e41883b\"}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "response\n",
    "# json_response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "591",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
