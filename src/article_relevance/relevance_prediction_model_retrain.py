# Author: Kelly Wu
# 2023-06-22

# Using corrected article relevance data to retrain the logistic regressio model
# Input: directory with the JSON files of new relevant articles & the parquet file with article info of the batch
# Output: Model object to be used for running the prediction pipeline

# Process Overview:
# - Gather the list of new data for training
# - Retried these article's feature from parquet file, convert to format that's suitable for model training
# - Spilt the new data into training split and test split. Default is 80%/20%, but user could modify the parameter in the train_test_split function.
# - Merge the new training split with old training split. Merge the test split with old test split.
# - Model retraining
# - Model evaluation

# Assumption:
# - All parquet files generated by the article relevance pipeline is stored in one single folder
# - All new articles's reviewed data outputted from data review tool are stored in one single folder (can contain subfolder).
# - Each parquet file contains doi, metadata, sentence embeddings, i.e. all info required for retraining

